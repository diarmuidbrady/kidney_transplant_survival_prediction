# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_eGFR_Prediction.ipynb.

# %% auto 0
__all__ = ['df_pheno', 'df_clust', 'evaluate_model']

# %% ../nbs/03_eGFR_Prediction.ipynb 4
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso
import xgboost as xgb
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from tabulate import tabulate

#df_pheno = pd.read_pickle('../data/proc/pheno.pkl')
df_pheno = pd.read_pickle('../../../D/2023-ca4021-bradyd-35-mcdaida-3/data/proc/pheno_imp.pkl') ## including eGFR scores
df_clust = pd.read_pickle('../../../D/2023-ca4021-bradyd-35-mcdaida-3/data/proc/pheno_eng.pkl')


# %% ../nbs/03_eGFR_Prediction.ipynb 7
def evaluate_model(predict, y_test):
    ### Calculate the mean squared error
    ## Average squared difference between the observed and the predicted values.
    ### Calculate the absolute errors
    ### Difference between the observed and the predicted values.
    ## R squared score
    ## Explains to what extent the variance of one variable explains the variance of the second variable.
    eval_dir = {}
    rmse = np.sqrt(mean_squared_error(y_test, predict))
    errors = abs(predict - y_test)
    mae = np.mean(errors)
    r_square = r2_score(y_test, predict)
    
    table = [['RMSE', 'MAE', 'R Squared'], [rmse, mae, r_square]]
    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56951cc-ce41-4817-a70d-34051c79ec60",
   "metadata": {},
   "source": [
    "# Running regression models on the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ae83a-03d4-482c-92a3-ca7a92f60ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07b69d-f5f8-4405-8627-d406c38b8242",
   "metadata": {},
   "source": [
    "## Import Modules and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21c9f3-db2a-4762-9d29-3d7b61ed0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import ttest_rel, ttest_ind\n",
    "\n",
    "df_pheno = pd.read_pickle('../../../D/2023-ca4021-bradyd-35-mcdaida-3/data/proc/pheno_cluster.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7416c7-3271-4c66-b465-f3c594290df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DonAge', 'RecAge', 'DonSex', 'RecSex', 'SexMismatch', 'Year',\n",
       "       'IntracranialHaemorrhage', 'RecPC1', 'RecHypertensionPRS',\n",
       "       'DonHypertensionPRS', 'DoneGFRPRS', 'DonStrokePRS', 'RecHAKVPRS',\n",
       "       'ColdIschemiaTime', 'GraftNo', 'eGFR1Year', 'eGFR5Year',\n",
       "       'GraftSurvivalDays', 'MClustClusters', 'KamilaClusters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e83531-e74c-4a7d-8779-43604f7a782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1878, 20)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pheno.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a5023-f181-485c-be75-c4e56a27630d",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "1. Convert categorical data to numerical.\n",
    "2. Dropping features that I am not including for now\n",
    "3. Remove null values from eGFR1year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6596a8-6164-4b36-bb9c-88978df4ba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DonAge                      float64\n",
       "RecAge                      float64\n",
       "DonSex                     category\n",
       "RecSex                     category\n",
       "SexMismatch                    bool\n",
       "Year                        float64\n",
       "IntracranialHaemorrhage        bool\n",
       "RecPC1                      float64\n",
       "RecHypertensionPRS          float64\n",
       "DonHypertensionPRS          float64\n",
       "DoneGFRPRS                  float64\n",
       "DonStrokePRS                float64\n",
       "RecHAKVPRS                  float64\n",
       "ColdIschemiaTime            float64\n",
       "GraftNo                     float64\n",
       "eGFR1Year                   float64\n",
       "eGFR5Year                   float64\n",
       "GraftSurvivalDays           float64\n",
       "MClustClusters             category\n",
       "KamilaClusters             category\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pheno.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56559f7e-9283-4d90-8eae-e5a61cdd353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing column MClustClusters from category to type int\n",
    "## ## Changing column KamilaClusters from category to type int\n",
    "## Changing column RecSex/DonSex from category to type int\n",
    "df_pheno['MClustClusters'] = df_pheno['MClustClusters'].astype(int)\n",
    "df_pheno['KamilaClusters'] = df_pheno['KamilaClusters'].astype(int)\n",
    "df_pheno['DonSex'].replace(['Male', 'Female'], [0,1], inplace=True)\n",
    "df_pheno['RecSex'].replace(['Male', 'Female'], [0,1], inplace=True)\n",
    "df_pheno['DonSex'] = df_pheno['DonSex'].astype(int)\n",
    "df_pheno['RecSex'] = df_pheno['RecSex'].astype(int)\n",
    "\n",
    "## Dropping 'eGFR5Year' and 'GraftSurvivalDays' as post transplant features\n",
    "df_pheno = df_pheno.drop(['eGFR5Year', 'GraftSurvivalDays'], axis = 1)\n",
    "\n",
    "## remove null values in eGFR 1 year\n",
    "df_pheno = df_pheno.dropna(subset=['eGFR1Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44005a-47ab-4fe3-8031-a526f5ec4c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DonAge                     float64\n",
       "RecAge                     float64\n",
       "DonSex                       int64\n",
       "RecSex                       int64\n",
       "SexMismatch                   bool\n",
       "Year                       float64\n",
       "IntracranialHaemorrhage       bool\n",
       "RecPC1                     float64\n",
       "RecHypertensionPRS         float64\n",
       "DonHypertensionPRS         float64\n",
       "DoneGFRPRS                 float64\n",
       "DonStrokePRS               float64\n",
       "RecHAKVPRS                 float64\n",
       "ColdIschemiaTime           float64\n",
       "GraftNo                    float64\n",
       "eGFR1Year                  float64\n",
       "MClustClusters               int64\n",
       "KamilaClusters               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pheno.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46deae7-d5be-4937-9692-f51f4445d847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DonAge</th>\n",
       "      <th>RecAge</th>\n",
       "      <th>DonSex</th>\n",
       "      <th>RecSex</th>\n",
       "      <th>SexMismatch</th>\n",
       "      <th>Year</th>\n",
       "      <th>IntracranialHaemorrhage</th>\n",
       "      <th>RecPC1</th>\n",
       "      <th>RecHypertensionPRS</th>\n",
       "      <th>DonHypertensionPRS</th>\n",
       "      <th>DoneGFRPRS</th>\n",
       "      <th>DonStrokePRS</th>\n",
       "      <th>RecHAKVPRS</th>\n",
       "      <th>ColdIschemiaTime</th>\n",
       "      <th>GraftNo</th>\n",
       "      <th>eGFR1Year</th>\n",
       "      <th>MClustClusters</th>\n",
       "      <th>KamilaClusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>0.574557</td>\n",
       "      <td>0.041781</td>\n",
       "      <td>-0.068460</td>\n",
       "      <td>-2.471242</td>\n",
       "      <td>-0.329893</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.016586</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.009447</td>\n",
       "      <td>-0.374240</td>\n",
       "      <td>0.829304</td>\n",
       "      <td>0.975353</td>\n",
       "      <td>0.069456</td>\n",
       "      <td>0.439058</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.068169</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.006079</td>\n",
       "      <td>0.050664</td>\n",
       "      <td>0.204120</td>\n",
       "      <td>-0.613161</td>\n",
       "      <td>-0.701665</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.602940</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.005711</td>\n",
       "      <td>-0.178995</td>\n",
       "      <td>0.322234</td>\n",
       "      <td>-0.446593</td>\n",
       "      <td>-0.399453</td>\n",
       "      <td>-1.000807</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.073505</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.010986</td>\n",
       "      <td>-0.090834</td>\n",
       "      <td>-0.195021</td>\n",
       "      <td>1.232662</td>\n",
       "      <td>1.297929</td>\n",
       "      <td>-1.184922</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.704456</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DonAge  RecAge  DonSex  RecSex  SexMismatch    Year  \\\n",
       "0    25.0    54.0       1       1         True  2000.0   \n",
       "1    37.0    35.0       0       0         True  2001.0   \n",
       "2    22.0    53.0       1       1         True  2002.0   \n",
       "3    48.0    33.0       1       0        False  2002.0   \n",
       "4    39.0    61.0       0       0         True  1999.0   \n",
       "\n",
       "   IntracranialHaemorrhage    RecPC1  RecHypertensionPRS  DonHypertensionPRS  \\\n",
       "0                    False -0.001810            0.574557            0.041781   \n",
       "1                    False -0.009447           -0.374240            0.829304   \n",
       "2                    False -0.006079            0.050664            0.204120   \n",
       "3                     True -0.005711           -0.178995            0.322234   \n",
       "4                    False -0.010986           -0.090834           -0.195021   \n",
       "\n",
       "   DoneGFRPRS  DonStrokePRS  RecHAKVPRS  ColdIschemiaTime  GraftNo  eGFR1Year  \\\n",
       "0   -0.068460     -2.471242   -0.329893            1080.0      1.0  37.016586   \n",
       "1    0.975353      0.069456    0.439058            1110.0      1.0  75.068169   \n",
       "2   -0.613161     -0.701665    0.004753            1102.0      1.0  59.602940   \n",
       "3   -0.446593     -0.399453   -1.000807             740.0      1.0  50.073505   \n",
       "4    1.232662      1.297929   -1.184922            1072.0      1.0  43.704456   \n",
       "\n",
       "   MClustClusters  KamilaClusters  \n",
       "0               3               4  \n",
       "1               3               1  \n",
       "2               3               4  \n",
       "3               1               3  \n",
       "4               3               5  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pheno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4abfd-ca81-42e2-88e3-e29746086b02",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcf4f2-2bc9-4e03-af54-b8e42a1ff829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_model(predict, y_test):\n",
    "    ### Calculate the mean squared error\n",
    "    ## Average squared difference between the observed and the predicted values.\n",
    "    ### Calculate the absolute errors\n",
    "    ### Difference between the observed and the predicted values.\n",
    "    ## R squared score\n",
    "    ## Explains to what extent the variance of one variable explains the variance of the second variable.\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predict))\n",
    "    errors = abs(predict - y_test)\n",
    "    mae = np.mean(errors)\n",
    "    r_square = r2_score(y_test, predict)\n",
    "    \n",
    "    table = [['RMSE', 'MAE', 'R Squared'], [rmse, mae, r_square]]\n",
    "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
    "    \n",
    "    ## Return list of errors in an array\n",
    "    difference = y_test - predict\n",
    "    error_array = np.array(difference)\n",
    "    return error_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7e3c7-0983-44f0-b04f-81aec3f9032e",
   "metadata": {},
   "source": [
    "# MClust Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9099bd6-9a30-4e7d-b669-1d0ab26c0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing KAMILA clusters\n",
    "df_mclust = df_pheno.drop(['KamilaClusters'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f136dc-326c-4922-9f17-c7952c80e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mclust['MClustClusters'].min(), df_mclust['MClustClusters'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d807b9a-62e0-4bd1-9c0d-6e6d7469c5c7",
   "metadata": {},
   "source": [
    "## Splitting the data based on cluster value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2b597-3b94-47b4-8321-f7cd0e30c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mclust_1 = df_mclust.loc[df_mclust.MClustClusters==1]\n",
    "df_mclust_2 = df_mclust.loc[df_mclust.MClustClusters==2]\n",
    "df_mclust_3 = df_mclust.loc[df_mclust.MClustClusters==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a021248-5d30-46b7-a083-12121e08f27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mclust_3['MClustClusters'].min(), df_mclust_3['MClustClusters'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a18655-a6d3-4910-a01b-256486ec3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_mclust_1.drop(['MClustClusters', 'eGFR1Year'], axis = 1)\n",
    "y1 = df_mclust_1['eGFR1Year']\n",
    "\n",
    "x2 = df_mclust_2.drop(['MClustClusters', 'eGFR1Year'], axis = 1)\n",
    "y2 = df_mclust_2['eGFR1Year']\n",
    "\n",
    "x3 = df_mclust_3.drop(['MClustClusters', 'eGFR1Year'], axis = 1)\n",
    "y3 = df_mclust_3['eGFR1Year']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b24f4-6805-467b-b39f-44e04ad39c54",
   "metadata": {},
   "source": [
    "## Splitting each dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb5c9b-ff3f-4108-9347-65a462bb9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.2, random_state=123)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=123)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d95a95-3213-42b6-b1ed-c103cd2247a0",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 1\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55388b-3138-4699-9d5c-a433dfb48092",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c917434-ad89-45d6-960d-356c152c8f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.5732 │ 13.2541 │    0.212628 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train1, y_train1)\n",
    "predicts = lin_reg.predict(x_test1)\n",
    "lin_error1 = evaluate_model(predicts, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da233efe-5090-484e-8047-fdede940a060",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf2fc5-1066-4461-8493-5542f9df9737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.5732 │ 13.2541 │    0.212628 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "# create linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lr, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "lin_error1 = evaluate_model(grid_search_pred, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66ed39-8f8b-426d-a722-92cff3720914",
   "metadata": {},
   "source": [
    "#### Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c0c2f-ac40-4231-bd27-21bfcd0711c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.3766 │ 13.0373 │    0.231199 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Apply L1 regularization using Lasso regression:\n",
    "lasso_model = Lasso(alpha=0.5)\n",
    "lasso_model.fit(x_train1, y_train1)\n",
    "y_pred_lasso = lasso_model.predict(x_test1)\n",
    "lin_error_use1 = evaluate_model(y_pred_lasso, y_test1)\n",
    "\n",
    "##Lasso regression can help to reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93becbd-691c-4515-9c87-ad39203627b3",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ceba96-ed67-4064-b975-ea9cb519f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 26.5064 │ 21.6227 │    -1.01405 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train1,y_train1)\n",
    "predicts = xg_reg.predict(x_test1)\n",
    "xg_error1 = evaluate_model(predicts, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5d24c-c9cb-499f-bd53-ccb46782c15b",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9251d4-fbdb-421e-ba91-c767d835ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.1537 │ 13.2975 │    0.251986 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "xg_error_use1 = evaluate_model(grid_search_pred, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffdc30d-7737-4924-9819-d04c6bfd254e",
   "metadata": {},
   "source": [
    "#### Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf26e6-157e-4f40-acd2-0e212d229221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.5462 │ 13.4405 │    0.215193 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Apply L1 regularization using the alpha parameter:\n",
    "\n",
    "xgb_model_l1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=123, n_estimators=1000, max_depth=5, learning_rate=0.1, alpha=0.5, colsample_bytree=0.5)\n",
    "xgb_model_l1.fit(x_train1,y_train1)\n",
    "predicts = xgb_model_l1.predict(x_test1)\n",
    "xg_error1 = evaluate_model(predicts, y_test1)\n",
    "\n",
    "##By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f6966-8dc9-44cf-8f79-ec2c23605ec5",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f55d8-cce1-4742-a8ac-f0b2b9863be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.4848 │ 13.6401 │    0.221002 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train1,y_train1)\n",
    "predictions = rf_reg.predict(x_test1)\n",
    "rf_error1 = evaluate_model(predictions, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb9b25-dee4-431d-afc8-8482f373e750",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b40811-8cd1-47d9-9b4b-83778a900095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤════════╤═════════════╕\n",
      "│    RMSE │    MAE │   R Squared │\n",
      "╞═════════╪════════╪═════════════╡\n",
      "│ 16.1891 │ 13.463 │    0.248698 │\n",
      "╘═════════╧════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "rf_error_use1 = evaluate_model(grid_search_pred, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6b5de-b0d9-463e-a9bf-d475cd4fde21",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d8b21-b9f4-4a2d-bb6a-61021366e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.4258 │ 13.6485 │    0.226568 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_model_l1 = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=123, ccp_alpha=0.5)\n",
    "rf_model_l1.fit(x_train1,y_train1)\n",
    "predictions = rf_model_l1.predict(x_test1)\n",
    "rf_error1 = evaluate_model(predictions, y_test1)\n",
    "\n",
    "## We are adding L1 regularization by setting the ccp_alpha parameter to 0.5. \n",
    "## The ccp_alpha parameter controls the complexity of the tree and can help to prevent overfitting. \n",
    "## By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2a205-98e4-48c7-b4ef-66429b879551",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477772a6-a783-449b-ae87-59811a71d4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤════════╤═════════════╕\n",
      "│    RMSE │    MAE │   R Squared │\n",
      "╞═════════╪════════╪═════════════╡\n",
      "│ 16.3345 │ 12.737 │    0.235147 │\n",
      "╘═════════╧════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train1,y_train1)\n",
    "predictions = svr_reg.predict(x_test1)\n",
    "svr_error_use1 = evaluate_model(predictions, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daee80d-a0a7-4005-b94f-577fd8257f37",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167c168-20b8-4544-bc97-a0f0a6aac4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.3386 │ 12.8898 │    0.234758 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "svr_error1 = evaluate_model(grid_search_pred, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff0486-b45d-43f7-aa3f-239550e3992f",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a51ed-c499-4166-ac8b-858322baac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.3572 │ 12.8447 │    0.233014 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_model_l1 = SVR(kernel='rbf', C=1.0, epsilon=0.1, coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter=-1, gamma='scale', degree=3)\n",
    "svr_model_l1.set_params(C=0.5, epsilon=0.2, kernel='linear')\n",
    "svr_model_l1.fit(x_train1,y_train1)\n",
    "predictions = svr_model_l1.predict(x_test1)\n",
    "svr_error1 = evaluate_model(predictions, y_test1)\n",
    "\n",
    "## We are adding L1 regularization by setting the C parameter to 0.5 and the kernel to 'linear'. \n",
    "## We are also setting the epsilon parameter to 0.2 to control the width of the epsilon-insensitive zone. \n",
    "## By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2912c9-4ac3-47f6-bf12-e0b2b0b5dc4e",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 2\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d488eb-e46e-4fbd-a7ac-e9d8d2c9d1db",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d4ff8-c342-4a33-90ed-b8c093507f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.8311 │ 13.4509 │    0.103644 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train2, y_train2)\n",
    "predicts = lin_reg.predict(x_test2)\n",
    "lin_error2 = evaluate_model(predicts, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ba777-cd82-4c9f-872c-8bb81a80b0f0",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84218e-643e-4e99-859b-e59765ecf50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.6241 │ 13.2563 │    0.125552 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "# create linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lr, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "lin_error2 = evaluate_model(grid_search_pred, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc1e0e-4178-4d7a-9fc6-d88627060d8f",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ce260-fd04-44d4-bcc8-01e497bd7874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.5095 │ 13.1655 │    0.137572 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Apply L1 regularization using Lasso regression:\n",
    "lasso_model = Lasso(alpha=0.5)\n",
    "lasso_model.fit(x_train2, y_train2)\n",
    "y_pred_lasso = lasso_model.predict(x_test2)\n",
    "lin_error_use2 = evaluate_model(y_pred_lasso, y_test2)\n",
    "\n",
    "##Lasso regression can help to reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172fca9-eaaa-4936-8e7f-b9e4391d01e9",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c6ce3-881e-4a8c-8c3c-79657339ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 25.2523 │ 20.7985 │    -1.01771 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train2,y_train2)\n",
    "predicts = xg_reg.predict(x_test2)\n",
    "xg_error2 = evaluate_model(predicts, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6594e-09c1-4211-b329-aa37e1d307ea",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09e088-d3fa-4764-99bd-ace9f6e2836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.8189 │ 13.3597 │    0.104945 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "xg_error_use2 = evaluate_model(grid_search_pred, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d221e8-5cad-4343-aef5-ca3cd6cd0c5b",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8c99d-dce2-4998-8681-3220f78cd738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.8387 │ 14.2114 │ -0.00689356 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Apply L1 regularization using the alpha parameter:\n",
    "\n",
    "xgb_model_l1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=123, n_estimators=1000, max_depth=5, learning_rate=0.1, alpha=0.5, colsample_bytree=0.5)\n",
    "xgb_model_l1.fit(x_train2,y_train2)\n",
    "predicts = xgb_model_l1.predict(x_test2)\n",
    "xg_error2 = evaluate_model(predicts, y_test2)\n",
    "\n",
    "##By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404005fb-4ee5-4481-9536-00f2b802e6bc",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea5908-8c6f-4673-a8c4-fd292e9cdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.9134 │ 12.8405 │    0.198725 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train2,y_train2)\n",
    "predictions = rf_reg.predict(x_test2)\n",
    "rf_error2 = evaluate_model(predictions, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1007b7-8dd5-4ef7-ae42-ff39e7ca5a06",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680c1cb-51c3-40fa-83af-4f73a9bc5e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.9673 │ 12.7441 │    0.193284 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "rf_error_use2 = evaluate_model(grid_search_pred, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128e1a6-3034-4d7a-9047-1987068f38b7",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756ccf0-1fce-472b-bb68-6d5722ec2b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.0055 │ 12.8786 │    0.189422 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_model_l1 = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=123, ccp_alpha=0.5)\n",
    "rf_model_l1.fit(x_train2,y_train2)\n",
    "predictions = rf_model_l1.predict(x_test2)\n",
    "rf_error2 = evaluate_model(predictions, y_test2)\n",
    "\n",
    "## We are adding L1 regularization by setting the ccp_alpha parameter to 0.5. \n",
    "## The ccp_alpha parameter controls the complexity of the tree and can help to prevent overfitting. \n",
    "## By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50dcdb-90be-4cc1-b47a-8543670fa1ab",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9a535-ee9c-4568-a9fe-0474d0cb3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.6197 │ 13.0975 │    0.126021 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train2,y_train2)\n",
    "predictions = svr_reg.predict(x_test2)\n",
    "svr_error2 = evaluate_model(predictions, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37822f-5e77-4607-8803-8b3c89a66aec",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d72fa-17a9-412b-bf0c-f21728e702b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.6954 │ 13.2443 │    0.118041 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "svr_error_use2 = evaluate_model(grid_search_pred, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6c8c6-9432-4d8c-9390-b689488881fb",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14968a58-36ef-4383-a771-699ae5278f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤═════════╤═════════════╕\n",
      "│   RMSE │     MAE │   R Squared │\n",
      "╞════════╪═════════╪═════════════╡\n",
      "│ 16.639 │ 13.1215 │    0.123983 │\n",
      "╘════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_model_l1 = SVR(kernel='rbf', C=1.0, epsilon=0.1, coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter=-1, gamma='scale', degree=3)\n",
    "svr_model_l1.set_params(C=0.5, epsilon=0.2, kernel='linear')\n",
    "svr_model_l1.fit(x_train2,y_train2)\n",
    "predictions = svr_model_l1.predict(x_test2)\n",
    "svr_error2 = evaluate_model(predictions, y_test2)\n",
    "\n",
    "## We are adding L1 regularization by setting the C parameter to 0.5 and the kernel to 'linear'. \n",
    "## We are also setting the epsilon parameter to 0.2 to control the width of the epsilon-insensitive zone. \n",
    "## By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878236e-ebb8-41d0-ab24-9dad5ae421c6",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 3\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ad5da-0f5b-4f8c-bc96-bff09f082d39",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4eece-37cb-43a5-841e-0fd1348000ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.2227 │ 12.2408 │    0.233061 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train3, y_train3)\n",
    "predicts = lin_reg.predict(x_test3)\n",
    "lin_error3 = evaluate_model(predicts, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db4516-15b5-42d7-b9aa-731f2b8660cd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5424508-b809-4f6e-89ce-c816b298a2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.2227 │ 12.2408 │    0.233061 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "# create linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lr, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "lin_error_use3 = evaluate_model(grid_search_pred, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9f311-03ed-4b07-822a-bddf0d5f0b2f",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b675bf5-29dd-4cdd-86aa-bb1fab056491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.1726 │ 12.0822 │    0.237795 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Apply L1 regularization using Lasso regression:\n",
    "lasso_model = Lasso(alpha=0.5)\n",
    "lasso_model.fit(x_train3, y_train3)\n",
    "y_pred_lasso = lasso_model.predict(x_test3)\n",
    "lin_error3 = evaluate_model(y_pred_lasso, y_test3)\n",
    "\n",
    "##Lasso regression can help to reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd521eb-02ac-4366-8682-d939ae822c11",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb826b0-17f7-43ec-8232-7e5ad31b1b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 27.7968 │ 22.8583 │    -1.25165 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train3,y_train3)\n",
    "predicts = xg_reg.predict(x_test3)\n",
    "xg_error3 = evaluate_model(predicts, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2c704-9924-463f-ad38-695dd1e01f9d",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eabdb2-0bd4-4924-a697-2ed00341b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.0036 │ 12.9782 │    0.157449 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "xg_error_use3 = evaluate_model(grid_search_pred, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8c7e9-ccff-4947-aab8-d74b8c6f6f14",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050285c0-0c5b-4387-b5f4-5b82b7de399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤════════╤═════════════╕\n",
      "│    RMSE │    MAE │   R Squared │\n",
      "╞═════════╪════════╪═════════════╡\n",
      "│ 17.6773 │ 13.595 │   0.0893599 │\n",
      "╘═════════╧════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Apply L1 regularization using the alpha parameter:\n",
    "\n",
    "xgb_model_l1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=123, n_estimators=1000, max_depth=5, learning_rate=0.1, alpha=0.5, colsample_bytree=0.5)\n",
    "xgb_model_l1.fit(x_train3,y_train3)\n",
    "predicts = xgb_model_l1.predict(x_test3)\n",
    "xg_error3 = evaluate_model(predicts, y_test3)\n",
    "\n",
    "##By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabba535-6dca-43ab-86f8-873680650db4",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e5cbf-ba60-490e-b765-88d79532ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.0738 │ 13.1958 │    0.150485 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train3,y_train3)\n",
    "predictions = rf_reg.predict(x_test3)\n",
    "rf_error_use3 = evaluate_model(predictions, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc63148-0225-4fc6-ae76-7e637d75eb1e",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0813b35-fb7a-4c4d-8e12-4a753e12bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.2144 │ 13.2035 │     0.13643 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "rf_error3 = evaluate_model(grid_search_pred, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6fc03-850a-4a3a-a191-63e497196cd7",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c89d1-6d0b-4cba-b888-b84d1782e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.1082 │ 13.3525 │    0.147057 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_model_l1 = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=123, ccp_alpha=0.5)\n",
    "rf_model_l1.fit(x_train3,y_train3)\n",
    "predictions = rf_model_l1.predict(x_test3)\n",
    "rf_error3 = evaluate_model(predictions, y_test3)\n",
    "\n",
    "## We are adding L1 regularization by setting the ccp_alpha parameter to 0.5. \n",
    "## The ccp_alpha parameter controls the complexity of the tree and can help to prevent overfitting. \n",
    "## By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2caf81-d72d-40c6-bca9-eb32d35b0a41",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da3ee0-c291-4c97-9bea-b0108f93860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.8411 │ 12.8622 │    0.173477 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train3,y_train3)\n",
    "predictions = svr_reg.predict(x_test3)\n",
    "svr_error3 = evaluate_model(predictions, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e0a86d-a963-46bc-b386-5042888f1d49",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb14492-1027-4f6b-9d61-84e98968e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.6726 │ 12.6173 │    0.189933 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "svr_error_use3 = evaluate_model(grid_search_pred, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72103f-45be-43b8-9931-3a3ff93bd905",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a29fd-f5aa-423b-9b60-1601fede6c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.7047 │ 12.7459 │    0.186813 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_model_l1 = SVR(kernel='rbf', C=1.0, epsilon=0.1, coef0=0.0, shrinking=True, tol=0.001, cache_size=200, \n",
    "                   verbose=False, max_iter=-1, gamma='scale', degree=3)\n",
    "svr_model_l1.set_params(C=0.5, epsilon=0.2, kernel='linear')\n",
    "svr_model_l1.fit(x_train3,y_train3)\n",
    "predictions = svr_model_l1.predict(x_test3)\n",
    "svr_error3 = evaluate_model(predictions, y_test3)\n",
    "\n",
    "## We are adding L1 regularization by setting the C parameter to 0.5 and the kernel to 'linear'. \n",
    "## We are also setting the epsilon parameter to 0.2 to control the width of the epsilon-insensitive zone. \n",
    "## By applying L1 regularization, we can reduce the impact of less important features on the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c19113-89ae-4620-aba6-e4dd78ab7f1c",
   "metadata": {},
   "source": [
    "# KAMILA Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bd65c-23a1-45f6-9470-7ec2670651ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DonAge                     float64\n",
       "RecAge                     float64\n",
       "DonSex                       int64\n",
       "RecSex                       int64\n",
       "SexMismatch                   bool\n",
       "Year                       float64\n",
       "IntracranialHaemorrhage       bool\n",
       "RecPC1                     float64\n",
       "RecHypertensionPRS         float64\n",
       "DonHypertensionPRS         float64\n",
       "DoneGFRPRS                 float64\n",
       "DonStrokePRS               float64\n",
       "RecHAKVPRS                 float64\n",
       "ColdIschemiaTime           float64\n",
       "GraftNo                    float64\n",
       "eGFR1Year                  float64\n",
       "MClustClusters               int64\n",
       "KamilaClusters               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pheno.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05fc07-64d1-4ab2-b110-d2b1e983129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing MClustClusters\n",
    "df_kclust = df_pheno.drop(['MClustClusters'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52157732-be94-4520-9158-94e0a6fece62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kclust['KamilaClusters'].min(), df_kclust['KamilaClusters'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de219277-6731-4d7b-bdb4-a02d2f2317fb",
   "metadata": {},
   "source": [
    "## Splitting the data based on the cluster values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75ecd6-1465-47fb-8040-ebffadab64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kclust_1 = df_kclust.loc[df_kclust.KamilaClusters==1]\n",
    "df_kclust_2 = df_kclust.loc[df_kclust.KamilaClusters==2]\n",
    "df_kclust_3 = df_kclust.loc[df_kclust.KamilaClusters==3]\n",
    "df_kclust_4 = df_kclust.loc[df_kclust.KamilaClusters==4]\n",
    "df_kclust_5 = df_kclust.loc[df_kclust.KamilaClusters==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a73fa-4343-42f3-9e6a-9cf681e21080",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_kclust_1.drop(['KamilaClusters', 'eGFR1Year'], axis = 1)\n",
    "y1 = df_kclust_1['eGFR1Year']\n",
    "\n",
    "x2 = df_kclust_2.drop(['KamilaClusters', 'eGFR1Year'], axis = 1)\n",
    "y2 = df_kclust_2['eGFR1Year']\n",
    "\n",
    "x3 = df_kclust_3.drop(['KamilaClusters', 'eGFR1Year'], axis = 1)\n",
    "y3 = df_kclust_3['eGFR1Year']\n",
    "\n",
    "x4 = df_kclust_4.drop(['KamilaClusters', 'eGFR1Year'], axis = 1)\n",
    "y4 = df_kclust_4['eGFR1Year']\n",
    "\n",
    "x5 = df_kclust_5.drop(['KamilaClusters', 'eGFR1Year'], axis = 1)\n",
    "y5 = df_kclust_5['eGFR1Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a0bb7-38e4-4ba1-aa12-720796fcf51c",
   "metadata": {},
   "source": [
    "## Splitting each dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4847f22-08aa-46a0-acb3-c79275a52205",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.2, random_state=123)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=123)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.2, random_state=123)\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x4, y4, test_size=0.2, random_state=123)\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(x5, y5, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb715049-f938-4b86-bddb-a5885b71aa04",
   "metadata": {},
   "source": [
    "## Cluster 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b7c00-ea5d-4101-afd7-4b48fa6c0314",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5708c13-88ca-4ee6-b236-5dc3742a5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.1373 │ 14.1517 │  -0.0279897 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train1, y_train1)\n",
    "predicts = lin_reg.predict(x_test1)\n",
    "error = evaluate_model(predicts, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6330b2-0791-488b-a237-30acfe5b31e6",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22aa894-256a-40c6-9491-3ae48505d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.6767 │ 13.4456 │   0.0265268 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'alpha': 0.1, 'fit_intercept': False, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "# create linear regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "lin_error1 = evaluate_model(grid_search_pred, y_test1)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48c09c-5c93-44ec-84aa-aecd6fee747e",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b0144-11a8-4eb7-b53d-ced9e2d07ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 29.0294 │ 24.6877 │    -1.94973 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train1,y_train1)\n",
    "predicts = xg_reg.predict(x_test1)\n",
    "xg_error1 = evaluate_model(predicts, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd110d28-1d15-4601-9cfa-81d6f98a0ea2",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1c3bb-ed47-421b-8e29-294d51244c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤════════╤═════════════╕\n",
      "│    RMSE │    MAE │   R Squared │\n",
      "╞═════════╪════════╪═════════════╡\n",
      "│ 15.7266 │ 12.915 │    0.134282 │\n",
      "╘═════════╧════════╧═════════════╛\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Combining regularization and hyperparameter tuning\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'learning_rate': [0.01, 0.1, 0.5],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'reg_alpha': [0.5],\n",
    "              'reg_lambda': [0.5]}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "xg_error1 = evaluate_model(grid_search_pred, y_test1)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89c871-fbea-4ed9-8af5-1521adc69f0f",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb97c8-6b16-40de-a098-60a92c6099b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.3111 │ 12.7206 │    0.179431 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train1,y_train1)\n",
    "predictions = rf_reg.predict(x_test1)\n",
    "rf_error1 = evaluate_model(predictions, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b8551-689c-41c1-914b-bab4cc3e89a0",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ede986-af59-44dc-9a14-ffd0be57c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤═════════╤═════════════╕\n",
      "│   RMSE │     MAE │   R Squared │\n",
      "╞════════╪═════════╪═════════════╡\n",
      "│ 15.335 │ 12.6996 │    0.176858 │\n",
      "╘════════╧═════════╧═════════════╛\n",
      "Best parameters: {'ccp_alpha': 0.5, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'ccp_alpha': [0.5]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "rf_error1 = evaluate_model(grid_search_pred, y_test1)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2066176-2b83-4e24-b10b-299ce003b7d2",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62a36b-7542-41b2-aad9-8dd0435b3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.4768 │ 14.2982 │  -0.0691224 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train1,y_train1)\n",
    "predictions = svr_reg.predict(x_test1)\n",
    "svr_error_use1 = evaluate_model(predictions, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59529640-7871-4411-97ec-e23c4c1a0e52",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b725796-5d75-4a1f-bb49-79309e6dc8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.5512 │ 13.0655 │   0.0411167 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test1)\n",
    "\n",
    "svr_error1 = evaluate_model(grid_search_pred, y_test1)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cb46e-1ad2-499e-bb6c-161d97697ce6",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 2\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aedc86-885d-4fef-bf7f-8abd60133021",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162ba8b-1069-4b76-9c12-6f333437e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.1971 │ 12.7902 │  -0.0365454 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train2, y_train2)\n",
    "predicts = lin_reg.predict(x_test2)\n",
    "lin_error2 = evaluate_model(predicts, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ce734-091f-4241-b8c5-cb66fe0f443a",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69e4c7-215b-4f1e-9343-0edb98182acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20040.260925360075, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21988.98153292983, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19902.917956887828, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20774.64169790573, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21348.11671933548, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20040.260925360075, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21988.98153292983, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19902.917956887828, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20774.64169790573, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21348.11671933548, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19144.005817201167, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21477.33397382117, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19425.306661924205, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20349.62720253123, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21033.895279223423, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19144.005817201167, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21477.33397382117, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19425.306661924205, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20349.62720253123, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21033.895279223423, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9380.999965811156, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16063.552402011572, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14177.418991527087, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15701.610313897203, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17553.954440987793, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9380.999965811156, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16063.552402011572, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14177.418991527087, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15701.610313897203, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17553.954440987793, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 476.747025640987, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4964.1266489487425, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1808.2567037065273, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2042.3546328422308, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3388.892704632781, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 476.747025640987, tolerance: 44.992676812803296\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4964.1266489487425, tolerance: 45.28663486877227\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1808.2567037065273, tolerance: 43.23567419336142\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2042.3546328422308, tolerance: 44.198312846968896\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3388.892704632781, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35193297541264, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35193297541264, tolerance: 43.16677743165128\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.8055 │ 12.1633 │   0.0129758 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'alpha': 1, 'fit_intercept': True, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "# create linear regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "lin_error2 = evaluate_model(grid_search_pred, y_test2)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69f450-1717-41c9-ba3f-26b60f140d94",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608246b7-11cf-4e6a-9c47-dcc918b9af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤═════════╤═════════════╕\n",
      "│   RMSE │     MAE │   R Squared │\n",
      "╞════════╪═════════╪═════════════╡\n",
      "│ 23.597 │ 18.8374 │    -1.20002 │\n",
      "╘════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train2,y_train2)\n",
    "predicts = xg_reg.predict(x_test2)\n",
    "xg_error2 = evaluate_model(predicts, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9b75b-e13f-45c5-9326-20bf89f95aa7",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac6b96-9428-4387-bd57-a0e5d0e81c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.8753 │ 12.6224 │  0.00423524 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Combining regularization and hyperparameter tuning\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'learning_rate': [0.01, 0.1, 0.5],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'reg_alpha': [0.5],\n",
    "              'reg_lambda': [0.5]}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "xg_error2 = evaluate_model(grid_search_pred, y_test2)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda99e5-caa7-42ca-bb95-d371d5c092e8",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b329bde-ffeb-4fad-8044-f158897d6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.3685 │ 12.1512 │   0.0667986 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train2,y_train2)\n",
    "predictions = rf_reg.predict(x_test2)\n",
    "rf_error2 = evaluate_model(predictions, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74e9f4-f396-48fe-8b30-51fbdbf4d4a3",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0e66d-2e9d-4d03-9030-a78f6b82bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.3793 │ 12.1898 │   0.0654917 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'ccp_alpha': 0.5, 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'ccp_alpha': [0.5]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "rf_error2 = evaluate_model(grid_search_pred, y_test2)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75efb3ce-9f29-471b-a4d3-84aca400dae0",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7558fdd-23d0-4883-921a-dc82c5042f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.4487 │ 12.6183 │  -0.0689904 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train2,y_train2)\n",
    "predictions = svr_reg.predict(x_test2)\n",
    "svr_error2 = evaluate_model(predictions, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991dff4-b20a-4f74-9e1d-a5eb24b23be6",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb96b6-7aac-4768-bdbe-0025357c02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.2793 │ 12.4047 │  -0.0470841 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train2, y_train2)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test2)\n",
    "\n",
    "svr_error2 = evaluate_model(grid_search_pred, y_test2)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64657a7-512f-4d66-8183-4678e231e3c2",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 3\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58f310-31ac-4bb6-9f63-da5ef7951d34",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37094921-18d0-454d-8cd5-f47013692392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.9203 │ 13.4708 │   0.0691534 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train3, y_train3)\n",
    "predicts = lin_reg.predict(x_test3)\n",
    "lin_error3 = evaluate_model(predicts, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb47951-e1c6-4e73-abc9-030ea0f71430",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618b67c-9382-4c47-89de-351a0f855a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤════════╤═════════════╕\n",
      "│    RMSE │    MAE │   R Squared │\n",
      "╞═════════╪════════╪═════════════╡\n",
      "│ 18.1133 │ 13.596 │   0.0489944 │\n",
      "╘═════════╧════════╧═════════════╛\n",
      "Best parameters: {'alpha': 0.1, 'fit_intercept': False, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "# create linear regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "lin_error3 = evaluate_model(grid_search_pred, y_test3)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17735f0a-ed52-4649-90d5-5bcc621a4a5a",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5f5e7-855f-433a-a73d-4afc82a8fede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 27.1018 │ 22.2032 │    -1.12903 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train3,y_train3)\n",
    "predicts = xg_reg.predict(x_test3)\n",
    "xg_error3 = evaluate_model(predicts, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55a7f2-2e49-4dfc-9d69-ad4e56e6b74c",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776abb2-5dbf-4e68-ac49-a35e50d0913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 19.0387 │ 14.3408 │  -0.0506554 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Combining regularization and hyperparameter tuning\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'learning_rate': [0.01, 0.1, 0.5],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'reg_alpha': [0.5],\n",
    "              'reg_lambda': [0.5]}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "xg_error3 = evaluate_model(grid_search_pred, y_test3)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49fa9b-6880-4c40-afa5-e6b2384dc539",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6402efa-6b13-4f18-b9ec-a500c1215d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤═════════╤═════════════╕\n",
      "│   RMSE │     MAE │   R Squared │\n",
      "╞════════╪═════════╪═════════════╡\n",
      "│ 17.913 │ 13.3223 │    0.069916 │\n",
      "╘════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train3,y_train3)\n",
    "predictions = rf_reg.predict(x_test3)\n",
    "rf_error_use3 = evaluate_model(predictions, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d035216-2a8a-4cdb-aad5-6c1e254eb825",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be28b89-e511-4050-b4c5-f9d1e67dbe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 18.2673 │ 13.7879 │   0.0327552 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'ccp_alpha': 0.5, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'ccp_alpha': [0.5]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "rf_error3 = evaluate_model(grid_search_pred, y_test3)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d46939-fa5f-4c7b-96e8-c7b1ec44f5f1",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5f33a-2a80-4a80-b524-dc52f67f73ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 18.2083 │ 13.7659 │   0.0389936 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train3,y_train3)\n",
    "predictions = svr_reg.predict(x_test3)\n",
    "svr_error3 = evaluate_model(predictions, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146962bb-5827-4cdc-a20f-02afcbeed860",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca269450-d336-4ccc-8759-348639452dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.7225 │ 13.3239 │   0.0895876 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train3, y_train3)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test3)\n",
    "\n",
    "svr_error3 = evaluate_model(grid_search_pred, y_test3)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9c2fc-fb71-4c12-8e9d-0884cc444afe",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 4\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8602c-b856-42d7-a480-1cad82143168",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f3262-552c-4907-85d3-2a877cc47a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 18.3882 │ 14.5975 │   -0.344816 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train4, y_train4)\n",
    "predicts = lin_reg.predict(x_test4)\n",
    "lin_error4 = evaluate_model(predicts, y_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7dcc8b-6ae8-4603-ba20-a1985e896587",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073bf3b-ba81-4649-9e26-9806df820ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1424.610532504972, tolerance: 50.637586033456664\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 985.9619703193566, tolerance: 49.47161664565706\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1424.610532504972, tolerance: 50.637586033456664\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 985.9619703193566, tolerance: 49.47161664565706\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.3739 │ 13.1981 │   -0.200554 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'alpha': 1, 'fit_intercept': True, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "# create linear regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train4, y_train4)\n",
    "grid_search_pred = grid_search.predict(x_test4)\n",
    "\n",
    "lin_error4 = evaluate_model(grid_search_pred, y_test4)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737ac8a-40e6-46ca-b238-b264555a67a7",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac5d78-e104-4467-a640-414dd67aebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 29.2988 │ 25.2185 │    -2.41417 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train4,y_train4)\n",
    "predicts = xg_reg.predict(x_test4)\n",
    "xg_error4 = evaluate_model(predicts, y_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d00a1-61f1-45a9-919f-4f5d1c359b4f",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e65d75-baeb-4324-bbc2-74dd3dd17ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 18.2315 │ 13.6225 │   -0.321991 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Combining regularization and hyperparameter tuning\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'learning_rate': [0.01, 0.1, 0.5],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'reg_alpha': [0.5],\n",
    "              'reg_lambda': [0.5]}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train4, y_train4)\n",
    "grid_search_pred = grid_search.predict(x_test4)\n",
    "\n",
    "xg_error4 = evaluate_model(grid_search_pred, y_test4)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9eb07-b8a5-495d-9fb8-feeb6abe69bc",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6890503-c3e6-43d0-ac08-b2d94ff3d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.8595 │ 12.6498 │   -0.130503 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train4,y_train4)\n",
    "predictions = rf_reg.predict(x_test4)\n",
    "rf_error4 = evaluate_model(predictions, y_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c916794-9f09-4a21-b574-296070137626",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f9cfe-37d8-456a-90d8-7931440f3a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═══════╤═════════════╕\n",
      "│    RMSE │   MAE │   R Squared │\n",
      "╞═════════╪═══════╪═════════════╡\n",
      "│ 17.1262 │ 13.29 │   -0.166557 │\n",
      "╘═════════╧═══════╧═════════════╛\n",
      "Best parameters: {'ccp_alpha': 0.5, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'ccp_alpha': [0.5]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train4, y_train4)\n",
    "grid_search_pred = grid_search.predict(x_test4)\n",
    "\n",
    "rf_error4 = evaluate_model(grid_search_pred, y_test4)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c26c87-a5a2-49fd-b4eb-56a8a1e35edb",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c0e05-b9b8-4119-bfcf-e59c1e20e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.4414 │ 13.3035 │   -0.209892 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train4,y_train4)\n",
    "predictions = svr_reg.predict(x_test4)\n",
    "svr_error4 = evaluate_model(predictions, y_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d16ea-ec3c-447b-9be7-2a74de1a0def",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560682d1-33ab-4196-a7a3-de02d759f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 17.1431 │ 13.2313 │   -0.168858 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train4, y_train4)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test4)\n",
    "\n",
    "svr_error4 = evaluate_model(grid_search_pred, y_test4)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc5894-0e79-4b7c-b9a3-44861d97ed8f",
   "metadata": {},
   "source": [
    "## Carrying out Machine learning on Cluster 5\n",
    "1. Linear Regression\n",
    "2. XGBoost Regression\n",
    "3. Random Forest Regression\n",
    "4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7fec14-3711-4476-83f2-dddf302df77e",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6c9c8-2b37-42fc-9fd8-59ea773910de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.6897 │ 12.4033 │  -0.0370005 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train5, y_train5)\n",
    "predicts = lin_reg.predict(x_test5)\n",
    "lin_error5 = evaluate_model(predicts, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ef632-14b3-437e-90aa-98c7234008e8",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84a5f2-546e-440e-a333-e6c959f87523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27740.106456764028, tolerance: 67.82149070234289\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26175.75592313746, tolerance: 67.60091510752183\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26417.454043183654, tolerance: 68.14476215190155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26390.021327483686, tolerance: 70.04142589016058\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23510.881955147204, tolerance: 66.82827499545805\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27740.106456764028, tolerance: 67.82149070234289\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26175.75592313746, tolerance: 67.60091510752183\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26417.454043183654, tolerance: 68.14476215190155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26390.021327483686, tolerance: 70.04142589016058\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23510.881955147204, tolerance: 66.82827499545805\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17167.233824186354, tolerance: 67.82149070234289\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14058.412010614702, tolerance: 67.60091510752183\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10395.785902068248, tolerance: 68.14476215190155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7908.086905922868, tolerance: 70.04142589016058\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2892.9540754282425, tolerance: 66.82827499545805\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17167.233824186354, tolerance: 67.82149070234289\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14058.412010614702, tolerance: 67.60091510752183\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10395.785902068248, tolerance: 68.14476215190155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7908.086905922868, tolerance: 70.04142589016058\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2892.9540754282425, tolerance: 66.82827499545805\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1461.4665444819548, tolerance: 67.82149070234289\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1073.8020427508673, tolerance: 67.60091510752183\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 477.64892077021796, tolerance: 68.14476215190155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 255.19016557110444, tolerance: 70.04142589016058\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1461.4665444819548, tolerance: 67.82149070234289\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1073.8020427508673, tolerance: 67.60091510752183\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 477.64892077021796, tolerance: 68.14476215190155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/users/k2252991/miniconda3/envs/db/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 255.19016557110444, tolerance: 70.04142589016058\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 16.2202 │ 12.9364 │   -0.108311 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'alpha': 1, 'fit_intercept': True, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "# create linear regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train5, y_train5)\n",
    "grid_search_pred = grid_search.predict(x_test5)\n",
    "\n",
    "lin_error5 = evaluate_model(grid_search_pred, y_test5)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28a932-b61c-446d-8e54-2aaf3a5f6826",
   "metadata": {},
   "source": [
    "### 2. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495a854-5a29-4874-8348-2d293f244921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 23.4932 │ 19.5428 │    -1.32507 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(x_train5,y_train5)\n",
    "predicts = xg_reg.predict(x_test5)\n",
    "xg_error5 = evaluate_model(predicts, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d9065-cbd8-4251-825c-0fdf9d6bfc22",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9327ac-24fa-4b39-b32e-6462fe6930b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.8401 │ 12.6523 │  -0.0569823 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Combining regularization and hyperparameter tuning\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'learning_rate': [0.01, 0.1, 0.5],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'reg_alpha': [0.5],\n",
    "              'reg_lambda': [0.5]}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xg_reg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train5, y_train5)\n",
    "grid_search_pred = grid_search.predict(x_test5)\n",
    "\n",
    "xg_error5 = evaluate_model(grid_search_pred, y_test5)\n",
    "\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac0cdd-52b4-4c83-a10b-740c9799cced",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac80259-582d-4fa4-845c-95a77bab0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.3542 │ 12.2607 │  0.00686932 │\n",
      "╘═════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_reg.fit(x_train5,y_train5)\n",
    "predictions = rf_reg.predict(x_test5)\n",
    "rf_error_use5 = evaluate_model(predictions, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f320f3b-c54c-4f29-bee1-af9bb0ee5115",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8852624-f677-4f39-b61b-1029198fed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.3228 │ 12.1498 │    0.010936 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'ccp_alpha': 0.5, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'ccp_alpha': [0.5]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train5, y_train5)\n",
    "grid_search_pred = grid_search.predict(x_test5)\n",
    "\n",
    "rf_error5 = evaluate_model(grid_search_pred, y_test5)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8704a1-e507-40c6-adf7-56aea2e0a11c",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1c0cb-74c6-4869-98cb-9b458a615785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤═════════╤═════════════╕\n",
      "│   RMSE │     MAE │   R Squared │\n",
      "╞════════╪═════════╪═════════════╡\n",
      "│ 15.373 │ 12.0874 │  0.00444092 │\n",
      "╘════════╧═════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "svr_reg = SVR(kernel = 'linear', C=1, epsilon=0.1)\n",
    "svr_reg.fit(x_train5,y_train5)\n",
    "predictions = svr_reg.predict(x_test5)\n",
    "svr_error5 = evaluate_model(predictions, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98be3e2-693d-4689-95db-43f0a8c2d75b",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a87fa-f6dc-4a87-94bd-6157b242b5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════════╤═════════════╕\n",
      "│    RMSE │     MAE │   R Squared │\n",
      "╞═════════╪═════════╪═════════════╡\n",
      "│ 15.4274 │ 12.3896 │ -0.00261412 │\n",
      "╘═════════╧═════════╧═════════════╛\n",
      "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVR model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train5, y_train5)\n",
    "\n",
    "grid_search_pred = grid_search.predict(x_test5)\n",
    "\n",
    "svr_error5 = evaluate_model(grid_search_pred, y_test5)\n",
    "## Printing the parameters that generated the best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab4df0-7e0c-43ca-bd8b-62e703e23e0e",
   "metadata": {},
   "source": [
    "# Evaluating Cluster Prediction Results\n",
    "1. Analyse cluster results and choose best model for each cluster\n",
    "2. Average the scores from each cluster to produce errors\n",
    "3. t-test to determine significant difference between the XGBoost previous and the clustered data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e3c37-e135-4e40-9900-03ed7fc8ddda",
   "metadata": {},
   "source": [
    "## 1. Results\n",
    "\n",
    "Best Model and resulting RMSE and R-Squared for each cluster.\n",
    "1. RFR - 15.335, 0.176858\n",
    "2. RFR - 15.3793, 0.0654917\n",
    "3. SVR - 17.7225, 0.0895876\n",
    "4. RFR - 17.1262, -0.166557\n",
    "5. RFR - 15.3228, 0.010936\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3b284-33b4-4e55-903b-a2751d863936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.17716"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculating the average RMSE and R-Squared\n",
    "\n",
    "sumRMSE = 15.335 + 15.3793 + 17.7225 + 17.1262 + 15.3228\n",
    "averageRMSE = sumRMSE / 5\n",
    "averageRMSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4817e9-e000-40c9-887c-b87a0506c3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03526326"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumR = 0.176858 + 0.0654917 + 0.0895876 + (-0.166557) + 0.010936\n",
    "averageR = sumR / 5\n",
    "averageR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a291dcd-7066-4908-b6ff-1b20f142e1ca",
   "metadata": {},
   "source": [
    "## Student T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699f2f5-3cf0-4445-b3ae-7fef0f96bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGError = np.array([-1.49930141e+01, -1.05391868e+01, -2.28876797e+01, -5.57648221e+00,\n",
    "       -8.77451437e+00,  2.48051978e+01,  1.47653985e+00, -6.33486857e+00,\n",
    "        4.61792870e+01,  6.44005270e+00, -1.32366804e+01, -1.27059778e+01,\n",
    "       -2.89741814e+00, -1.96761159e+00, -2.00630232e+01,  7.80281890e+00,\n",
    "       -2.95987886e+01, -1.37410507e+01,  1.01659603e+01,  3.97299456e+00,\n",
    "        1.38344183e+01, -1.57039601e+01, -3.88069447e+00,  2.27151903e+01,\n",
    "        2.11823201e+01,  3.09669242e+01,  1.95808960e+01, -2.07234200e+01,\n",
    "       -1.10437354e+01, -3.01690782e+00,  2.14914611e+01, -5.19517385e+00,\n",
    "        2.46319871e+01, -3.31543344e+00,  1.80235940e+01, -9.56499256e+00,\n",
    "       -9.92516499e-01,  4.19898753e+00,  7.36667482e-02,  1.40164645e+01,\n",
    "       -7.86428163e+00, -1.39020197e+01, -2.18899131e+01, -1.02733649e+01,\n",
    "       -1.56543003e+01, -2.44553433e+01,  1.37606358e+00, -5.42034620e+00,\n",
    "       -3.18388223e+01, -1.22763792e+01, -6.31948420e+00,  1.19252618e+01,\n",
    "       -2.68161443e+00,  1.08115435e+01,  1.61543720e+01, -1.32026894e+01,\n",
    "       -1.99664792e+01, -1.25157095e+01,  7.84949842e+00, -9.09626558e+00,\n",
    "        2.83582583e-01,  1.64829847e+01, -1.63520003e+01, -6.80884870e+00,\n",
    "        7.56051622e+00,  8.61054400e+00, -1.35872271e+01, -3.00533002e+00,\n",
    "       -8.40634336e+00,  2.36423995e+01, -1.34421109e+01,  2.16712957e-01,\n",
    "        1.63225581e+01, -1.00933719e+01, -1.27840793e+01,  1.61993888e+01,\n",
    "       -1.15606374e+01,  2.77314959e+00, -6.30839841e+00, -3.22966041e-01,\n",
    "        2.19677191e+01, -9.97578772e+00, -1.30084042e+01, -7.12404108e+00,\n",
    "       -6.58753150e+00,  8.73450175e+00, -1.48527927e-02, -1.95438410e+01,\n",
    "       -2.53688981e+00, -2.12319329e-01, -2.25116903e+01,  1.49873933e+01,\n",
    "       -1.76085508e+01, -1.08776291e+01, -3.88609236e-01, -6.21969551e+00,\n",
    "       -1.89662218e+01, -9.72874792e+00,  1.07893609e+01, -2.06914687e+01,\n",
    "       -1.35700612e+00, -2.05220639e+01,  2.60096593e+00,  3.29990422e+01,\n",
    "        5.89199518e+00, -1.24953546e+00,  1.73845348e+01, -4.21492511e+00,\n",
    "        1.52851166e+01, -6.91719769e+00, -1.33298857e+01,  2.15751711e+01,\n",
    "        6.88017902e+00, -1.23764581e+01,  2.37540663e+00, -7.35959196e+00,\n",
    "       -9.13404968e+00,  6.13457601e+00,  1.34922507e+01, -1.62509093e+01,\n",
    "       -1.25583144e+01,  1.43031578e+01, -9.86035365e+00, -5.04106702e+00,\n",
    "       -2.42061427e+00,  3.82688791e+00,  1.93612844e+01, -2.76980389e+01,\n",
    "       -2.27479302e+00, -6.62757928e+00,  1.39671447e+01, -1.32880566e+01,\n",
    "        2.34751117e+01,  8.35911371e+00,  1.33979070e+00, -2.26170200e+01,\n",
    "       -3.52700626e+00,  2.09248042e+00, -8.32927635e+00,  1.03610363e+01,\n",
    "        8.54605225e+00,  2.49819369e+01,  1.47744144e+01,  5.00630885e+00,\n",
    "        3.20212942e+00, -1.44215769e+01,  1.12022048e+01,  9.21048953e+00,\n",
    "       -1.51147398e+00,  1.69821621e+01,  1.91685442e+01, -1.22319686e+01,\n",
    "       -1.33281251e+01, -1.30768485e+01, -2.12449421e+01,  4.26985791e+00,\n",
    "        4.30423210e+01, -7.01209005e+00,  2.53399401e+01, -1.40437381e+01,\n",
    "       -2.30243780e+01, -9.53316099e+00, -2.84378407e+01, -9.98043045e+00,\n",
    "       -1.88538999e+01,  8.36485296e+00, -7.37331318e+00,  1.58260296e+00,\n",
    "        4.60100547e+00, -3.15724209e+00,  4.83556680e+00,  1.36344079e+01,\n",
    "        4.24354616e-01, -9.13472577e+00, -1.04129518e+01,  1.35597047e+01,\n",
    "        4.16861737e+01, -1.60500477e+01, -2.45157770e+01,  4.98308269e+01,\n",
    "        2.48720811e+01,  1.22703159e+01,  1.86726374e+01, -2.04306458e+01,\n",
    "        1.42479339e+01, -1.96266053e+01, -5.60695201e+00,  1.94340720e+01,\n",
    "        2.40868443e+01,  1.76832983e+01,  1.01662904e+01, -8.90735914e+00,\n",
    "       -5.57777784e+00,  3.49917722e+01, -9.01888824e+00, -6.23040669e+00,\n",
    "        2.56289658e+01,  7.85200291e+00,  1.79460587e+01, -1.82618168e+01,\n",
    "       -6.75668686e+00,  5.32840371e+00,  1.93551994e+01,  1.27487651e+01,\n",
    "       -3.00986259e+01,  2.51873873e+01,  3.22827475e+01, -7.05218826e+00,\n",
    "       -1.21465570e+00,  6.45410539e+00, -9.27516992e+00,  3.69940489e+00,\n",
    "        8.09052027e+00,  3.44840142e+00, -2.27953254e+01, -5.88707282e+00,\n",
    "       -1.45219543e+01,  4.10595158e+00, -6.24087995e+00, -2.16154337e+01,\n",
    "       -4.85071534e+00, -1.54410664e+00, -2.45990743e+01, -1.93091584e+01,\n",
    "        2.68235841e+01,  7.91804730e+00, -1.77968565e+01,  1.18970440e+01,\n",
    "       -5.23247229e+00,  3.45594218e+01,  2.09748079e+01, -1.15721868e+01,\n",
    "       -2.90559928e+01, -1.42283791e+01,  1.89928025e+01, -7.08926742e+00,\n",
    "        8.68237321e+00, -7.44196642e-01,  7.84147817e-01, -4.45033396e+00,\n",
    "       -3.34914994e+00, -1.98789287e+01,  1.62509104e+01, -4.71212337e+00,\n",
    "       -3.47985020e+00,  7.25475934e+00,  3.55735568e+00,  1.05179621e+01,\n",
    "       -2.32680968e+00,  4.27055320e+01, -9.27691065e+00,  2.31746986e+01,\n",
    "       -1.81204600e+01, -5.02341170e-01, -2.26571438e+01, -3.97284827e+01,\n",
    "       -2.59066582e+01,  1.51269015e+01,  3.84963292e+00, -6.87070045e+00,\n",
    "       -1.68441822e+01, -5.61200503e+00, -2.48155927e+01, -2.44082756e+01,\n",
    "       -6.84623535e+00, -1.27387784e+01, -1.36952768e+01,  7.03011931e+00,\n",
    "       -3.26094271e+00,  5.17194848e+00, -8.53576933e+00,  7.54840700e+00,\n",
    "       -1.06420851e+01,  3.34901211e+00,  6.70479721e+00,  1.35097442e+01,\n",
    "       -4.23829637e+00, -3.35112231e+00,  3.33642512e+00, -2.58237802e+01,\n",
    "        3.99886997e+00, -4.39409822e+00,  5.29665789e+00,  5.80445717e-01,\n",
    "        1.70016914e+01,  5.95002349e+00, -1.28830396e+01, -9.60932012e+00,\n",
    "       -7.04938505e+00,  8.14227251e+00,  9.51256744e+00, -2.39737655e+01,\n",
    "       -2.59570567e+00, -8.33122184e+00, -4.46079856e+00, -1.17284090e+01,\n",
    "       -1.08156548e+01,  4.67349430e-01,  3.32044820e+01, -1.20561734e+01,\n",
    "       -9.08896241e+00,  1.32767485e+01, -6.19532068e+00, -7.03304409e+00,\n",
    "        1.96759471e+01, -1.25877281e+01,  2.04535034e+01,  1.00551005e+01,\n",
    "       -9.69625254e+00, -6.14030927e+00, -1.48899146e+01, -8.05146086e+00,\n",
    "        1.20855945e+01, -3.20091939e+00,  5.02771147e+00, -1.31742192e+01,\n",
    "       -2.09159919e+01,  3.73850873e+00, -5.03880064e+00, -7.35948309e-02,\n",
    "        2.11833564e+00, -1.69549719e+01, -1.95176674e+00])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc7cfc-570f-4d5f-9c4f-946bf9e529e9",
   "metadata": {},
   "source": [
    "### Comparing XGBoost overall to Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d209b91-660c-451c-9a53-94a75150b4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test results:\n",
      "t-statistic: 0.6878684398619253\n",
      "p-value: 0.49196546273370145\n",
      "The difference between the RMSE scores is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "## Using python package\n",
    "# Perform t-test\n",
    "# lin_error = array of errors generated from the linear regression model\n",
    "# xg_error = array of errors generated from the xgboost regression model\n",
    "\n",
    "t_statistic, p_value = ttest_ind(rf_error1, XGError)\n",
    "# Print the results\n",
    "print(\"Paired t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Compare the p-value with a significance level alpha (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the RMSE scores is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the RMSE scores is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b260894-4052-42a5-a709-68a12422d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test results:\n",
      "t-statistic: 1.664455510049037\n",
      "p-value: 0.09681644661716271\n",
      "The difference between the RMSE scores is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "## Using python package\n",
    "# Perform t-test\n",
    "# lin_error = array of errors generated from the linear regression model\n",
    "# xg_error = array of errors generated from the xgboost regression model\n",
    "\n",
    "t_statistic, p_value = ttest_ind(rf_error2, XGError)\n",
    "# Print the results\n",
    "print(\"Paired t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Compare the p-value with a significance level alpha (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the RMSE scores is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the RMSE scores is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b089350-8079-4cab-a511-e7c705671958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test results:\n",
      "t-statistic: 1.7216458363376803\n",
      "p-value: 0.08589727732947233\n",
      "The difference between the RMSE scores is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "## Using python package\n",
    "# Perform t-test\n",
    "# lin_error = array of errors generated from the linear regression model\n",
    "# xg_error = array of errors generated from the xgboost regression model\n",
    "\n",
    "t_statistic, p_value = ttest_ind(svr_error3, XGError)\n",
    "# Print the results\n",
    "print(\"Paired t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Compare the p-value with a significance level alpha (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the RMSE scores is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the RMSE scores is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0aa68-e91a-40ce-abae-bb166af058e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test results:\n",
      "t-statistic: 0.7996968085529483\n",
      "p-value: 0.42441236815203187\n",
      "The difference between the RMSE scores is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "## Using python package\n",
    "# Perform t-test\n",
    "# lin_error = array of errors generated from the linear regression model\n",
    "# xg_error = array of errors generated from the xgboost regression model\n",
    "\n",
    "t_statistic, p_value = ttest_ind(rf_error4, XGError)\n",
    "# Print the results\n",
    "print(\"Paired t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Compare the p-value with a significance level alpha (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the RMSE scores is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the RMSE scores is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ef7ad-6d1c-4d7d-8c05-1df585479027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test results:\n",
      "t-statistic: 0.5324319496626041\n",
      "p-value: 0.5947232288822357\n",
      "The difference between the RMSE scores is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "## Using python package\n",
    "# Perform t-test\n",
    "# lin_error = array of errors generated from the linear regression model\n",
    "# xg_error = array of errors generated from the xgboost regression model\n",
    "\n",
    "t_statistic, p_value = ttest_ind(rf_error5, XGError)\n",
    "# Print the results\n",
    "print(\"Paired t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Compare the p-value with a significance level alpha (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the RMSE scores is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the RMSE scores is not statistically significant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
